{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aKiUhyOLBKtP"},"outputs":[],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9oZqKDlBOMC"},"outputs":[],"source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCmsPvAQBPCu"},"outputs":[],"source":["!kaggle competitions download -c dogs-vs-cats\n","!unzip -qq dogs-vs-cats.zip\n","!unzip -qq train.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcsXb9sRAdqX"},"outputs":[],"source":["import os, shutil, pathlib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from keras import layers\n","from keras.utils import image_dataset_from_directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djKBdb4aBXmX"},"outputs":[],"source":["original_dir = pathlib.Path(\"train\")\n","new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n","\n","def make_subset(subset_name, start_index, end_index):\n","    for category in (\"cat\", \"dog\"):\n","        dir = new_base_dir / subset_name / category\n","        os.makedirs(dir)\n","        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n","        for fname in fnames:\n","            shutil.copyfile(src=original_dir / fname,\n","                            dst=dir / fname)\n","\n","make_subset(\"train\", start_index=0, end_index=1000)\n","make_subset(\"validation\", start_index=1000, end_index=1500)\n","make_subset(\"test\", start_index=1500, end_index=2500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDf8GopOBYcV"},"outputs":[],"source":["train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVEfmsMxCxHV"},"outputs":[],"source":["conv_base  = keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False)\n","conv_base.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WBLq4OsGM-R"},"outputs":[],"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.2),\n","    ]\n",")\n","\n","inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = keras.applications.vgg16.preprocess_input(x)\n","x = conv_base(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"fine_tuning.tf\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=50,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"F2DNq0qsO-fD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"id":"Smzycq2lPDhk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.trainable = True\n","for layer in conv_base.layers[:-4]:\n","  layer.trainable = False"],"metadata":{"id":"Cjj7Pj2h-M7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ec_mw-JHY0q"},"outputs":[],"source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"fine_tuning.tf\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=30,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FH4QO-ELdpp8"},"outputs":[],"source":["accuracy = history.history[\"accuracy\"]\n","val_accuracy = history.history[\"val_accuracy\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(accuracy) + 1)\n","plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n","plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n","plt.title(\"Training and validation accuracy\")\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n","plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n","plt.title(\"Training and validation loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZee71Yndu5E"},"outputs":[],"source":["model = keras.models.load_model(\"fine_tuning.tf\")\n","test_loss, test_acc = model.evaluate(test_dataset)\n","print(f\"Test accuracy: {test_acc:.3f}\")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1V8qArg9nYpxqybqX-00NibRqUBG8xTyg","timestamp":1701142008852},{"file_id":"1dPKDP_lgaitrSxNyRC31btJFLS6PCcdJ","timestamp":1701139136110},{"file_id":"10Hcu632Ft6XBpoJ33p8ASusGdFkCgnaB","timestamp":1701074024942},{"file_id":"1aw64VGAIARINbBff0GLKhmkVoLnDyQjU","timestamp":1700756952098}],"gpuType":"T4","authorship_tag":"ABX9TyNb9UTDSwI+VbMvf4qGts1+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}